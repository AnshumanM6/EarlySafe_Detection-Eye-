# -*- coding: utf-8 -*-
"""Cataract_EfficientB0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OrA2QLExR8E6s2pI016z5ZWtV9-4ZkFs
"""

"""
Code for Transfer learning using EfficientNetB0. 
Currently Trained on Kaggle Cataract Dataset 400 images -> 300 negative, 100 positive

Example to use model :

'''
model = tensorflow.keras.model.load(path_to_modelFile)
X : preprocessed input 
    dtype: np array 
    size = (300,300,3) 

prediction : np array for each data point . Each np array has probability of class 0(negative) and class 1(positive) 


prediction = model.predict([X])
 
'''

"""



# Model building starts here
import os
import random
from shutil import copyfile
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import Model
import efficientnet.tfkeras as efn
from efficientnet import preprocessing
from tensorflow.keras import models
from tensorflow.keras import layers
from tensorflow.keras.optimizers import RMSprop
import matplotlib.pyplot as plt
import cv2
import numpy as np

# Change this path to required path to save the model
checkpoint_filepath = '/content/gdrive/My Drive/Pixel_AI/Cataract_EffNetB0.h5'

# callback to save best accuracy result
model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    #save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25,
                              patience=7, min_lr=0.00001)

def build_model():
  Net = efn.EfficientNetB0(input_shape=(300,300,3), weights='imagenet', include_top=False)
  input_shape = (300,300,3)
  conv_base = Net
  # Train the whole model from scratch
  conv_base.trainable = True
  dropout_rate = 0
  model = models.Sequential()
  model.add(conv_base)
  model.add(layers.GlobalMaxPooling2D(name="gap"))
  model.add(layers.Dense(1024,activation="relu",name="fc"))
  if dropout_rate > 0:
      model.add(layers.Dropout(dropout_rate, name="dropout_out"))
  model.add(layers.Dense(1, activation="sigmoid", name="fc_out"))
  
  return model

model = build_model()

model.summary()

X_train,y_train = [],[]
X_test,y_test = [],[]

def preprocess_and_create_train():
  total = []
  for f in os.listdir('/content/training/positive'):
    im = cv2.imread('/content/training/positive/'+f)
    im=preprocessing.center_crop_and_resize(im,300)
    total.append((im,1))

  for f in os.listdir('/content/training/negative'):
    im = cv2.imread('/content/training/negative/'+f)
    im=preprocessing.center_crop_and_resize(im,(300))
    total.append((im,0))

  random.shuffle(total)

  for (im,label) in total:
    X_train.append(im)
    y_train.append(label)


def preprocess_and_create_test():
  total = []
  for f in os.listdir('/content/testing/positive'):
    im = cv2.imread('/content/testing/positive/'+f)
    im=preprocessing.center_crop_and_resize(im,300)
    total.append((im,1))

  for f in os.listdir('/content/testing/negative'):
    im = cv2.imread('/content/testing/negative/'+f)
    im=preprocessing.center_crop_and_resize(im,(300))
    total.append((im,0))

  random.shuffle(total)
  
  for (im,label) in total:
    X_test.append(im)
    y_test.append(label)

preprocess_and_create_train()
preprocess_and_create_test()

# Reshape the array to input into the model
X_train = np.array(X_train)
X_train = np.reshape(X_train,(-1,300,300,3))
X_test = np.array(X_test)
X_test = np.reshape(X_test,(-1,300,300,3))
y_train = np.array(y_train)
y_test = np.array(y_test)

def model_train():
  model.compile(optimizer = RMSprop(lr = 0.0001), 
                loss = "binary_crossentropy", 
                metrics = ["accuracy",tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]
                
  )
  history = model.fit(X_train,y_train,epochs=40,verbose=1,validation_data = (X_test,y_test),callbacks = [model_checkpoint_callback],class_weight = {0:2,1:0.66})
  return history

history = model_train()

# Function to plot different metrics
def plot_metrics():
  loss = history.history['loss']
  val_loss = history.history['val_loss']
  acc = history.history['accuracy']
  val_acc = history.history['val_accuracy']
  plt.plot(acc)
  plt.plot(val_acc)
  plt.legend(['acc','val_acc'])
  plt.show()

plot_metrics()
